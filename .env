# Context Engineering Demo - Environment Configuration Template
# Copy this file to .env and fill in your API keys

# =============================================================================
# AI Provider Configuration
# =============================================================================

# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-3.5-turbo
# OPENAI_BASE_URL=https://api.openai.com/v1  # Optional: custom base URL

# Anthropic Configuration  
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ANTHROPIC_MODEL=claude-3-haiku-20240307
# ANTHROPIC_BASE_URL=https://api.anthropic.com  # Optional: custom base URL

# Google Gemini Configuration
GEMINI_API_KEY=AIzaSyBQ0QfK-lT2xKXhEDTdH5nqw3o1lj9OIUc
GEMINI_MODEL=gemini-1.5-flash
# GEMINI_BASE_URL=https://generativelanguage.googleapis.com  # Optional: custom base URL

# OpenRouter Configuration
OPENROUTER_API_KEY=your_openrouter_api_key_here
OPENROUTER_MODEL=openai/gpt-3.5-turbo
# OPENROUTER_BASE_URL=https://openrouter.ai/api/v1  # Optional: custom base URL

# =============================================================================
# Application Settings
# =============================================================================

# Default AI provider (openai, anthropic, gemini, openrouter)
AI_PROVIDER=gemini

# AI Model Parameters
AI_TEMPERATURE=0.7
AI_MAX_TOKENS=500
AI_TIMEOUT=30

# Application Settings
APP_TITLE=Context Engineering Demo
ENABLE_CACHING=true
LOG_LEVEL=INFO

# =============================================================================
# Development Settings
# =============================================================================

# Set to true for development mode
DEBUG=false

# Cache settings
CACHE_TTL=3600

# Context settings
MAX_CONTEXT_SIZE=10000
CONTEXT_REFRESH_INTERVAL=300
